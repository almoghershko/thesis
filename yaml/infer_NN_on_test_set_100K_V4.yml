apiVersion: batch/v1
kind: Job
metadata:
  name: almoghershko-infer
spec:
  backoffLimit: 0
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-GeForce-RTX-2080-Ti
                - NVIDIA-GeForce-RTX-3090
                - Tesla-V100-SXM2-32GB
      containers:
      - name: container
        image: almogh/tf-almog
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "4"
            memory: "128Gi"
            nvidia.com/gpu:  "1"
          limits:
            cpu: "4"
            memory: "128Gi"
            nvidia.com/gpu:  "1"
        command: ["/bin/bash", "-c"]
        args:
          - cd root; 
            git clone https://github.com/almoghershko/thesis.git;
            dt=$(date '+%Y_%m_%d__%H_%M_%S');
            run_name="$RUN_PREFIX"__"$dt";
            NN_save_name="LongTrainV4___2022_05_09___07_29_04___Kernels_31_Filters_64_32_16_8_4_Hiddens_512_128_tanh"
            pip install -r thesis/requirements.txt;
            python thesis/scripts/run_infer_on_test_set_100K_V4.py $run_name $NN_save_name &> stdout.txt;
            aws --endpoint https://s3-west.nrp-nautilus.io s3 cp ./stdout.txt s3://tau-astro/almogh/workdir3/runs/$run_name/;
        env:
          - name: "RUN_PREFIX"
            value: "InferV4"
      restartPolicy: Never
