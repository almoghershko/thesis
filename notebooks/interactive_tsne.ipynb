{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 progressbar2 sfdmap GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install typing-extensions --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"holoviews[recommended]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import boto3\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# local files paths\n",
    "local_home_dir_path = os.path.expanduser(\"~\")\n",
    "local_work_dir_path = os.path.join(local_home_dir_path, 'git')\n",
    "local_code_dir_path = os.path.join(local_work_dir_path , 'code')\n",
    "\n",
    "# S3 file paths\n",
    "endpoint_url = 'https://s3.nautilus.optiputer.net'\n",
    "bucket_name = 'tau-astro'\n",
    "prefix = 'almogh'\n",
    "s3_work_dir_path = os.path.join(prefix, 'workdir3')\n",
    "s3_saves_dir_path = os.path.join(s3_work_dir_path , 'model_saves')\n",
    "s3_data_dir_path = os.path.join(s3_work_dir_path , 'data')\n",
    "s3_data_ver_dir_path = os.path.join(s3_data_dir_path,'HighSNR_12K_V1')\n",
    "\n",
    "s3_client = boto3.client(\"s3\", endpoint_url=endpoint_url)\n",
    "\n",
    "# adding code folder to path\n",
    "sys.path.insert(1, local_code_dir_path)\n",
    "from s3 import to_s3_npy, to_s3_pkl, from_s3_npy, from_s3_pkl, to_s3_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_name = 'simple___2021_11_27___22_09_00___standard_RF_max_depth_10'\n",
    "s3_rf_save_dir_path = os.path.join(s3_saves_dir_path, 'RF', save_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading saved data')\n",
    "I_slice = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'I_slice.npy'))\n",
    "I_train = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'I_train.npy'))\n",
    "X_train_real = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'X.npy'))\n",
    "X_leaves_train_real = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'X_leaves.npy'))\n",
    "Y_hat_train_real = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'Y_hat.npy'))\n",
    "weird_scores = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'weird_scores.npy'))\n",
    "sne = from_s3_npy(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'tsne.npy'))\n",
    "\n",
    "print('Loading wavelength grid and dataframe')\n",
    "wl_grid = from_s3_npy(s3_client, bucket_name, os.path.join(s3_data_dir_path, 'wl_grid.npy'))\n",
    "gs = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_data_ver_dir_path, 'gs.pkl'))\n",
    "I_real_train = I_train[I_train<len(I_slice)]\n",
    "snr = gs.snMedian.iloc[I_slice[I_real_train]]\n",
    "\n",
    "print('Loading random forest')\n",
    "from CustomRandomForest import CustomRandomForest\n",
    "rf = CustomRandomForest.load_s3(s3_client, bucket_name, os.path.join(s3_rf_save_dir_path, 'crf.pkl'))\n",
    "\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from holoviews.streams import Selection1D\n",
    "from bokeh.models import HoverTool\n",
    "from scipy import stats\n",
    "import panel as pn\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creading the dataframe\n",
    "df = pd.DataFrame(sne, columns=['feature_1', 'feature_2'])\n",
    "df['score'] = weird_scores\n",
    "df['snr'] = snr\n",
    "df['index'] = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_dmap_callable(color_src):\n",
    "    \"\"\"\n",
    "    The callable function for the points DynamicMap.\n",
    "    \"\"\"\n",
    "    points = hv.Points(df).opts(color=color_src, cmap='jet')\n",
    "    points.opts(tools=['tap','box_select','lasso_select'])\n",
    "    points.opts(selection_alpha=0.4, nonselection_alpha=0.1)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def spectra_dmap_callable(index):\n",
    "    \"\"\"\n",
    "    The callable function for the spectra DynamicMap.\n",
    "    \"\"\"\n",
    "    with open('/home/jovyan/debug.txt','w') as f:\n",
    "        f.write('in spectra_dmap_callable - '+datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")+'\\n')\n",
    "        if len(index)==0:\n",
    "            f.write('len==0\\n')\n",
    "            # No Selection\n",
    "            x = np.zeros(shape=wl_grid.shape)\n",
    "            w = wl_grid\n",
    "            label = 'No Selection'\n",
    "        else:\n",
    "            f.write('len!=0\\n')\n",
    "            x = np.nanmean(X_train_real[index], axis=0)\n",
    "            x_valid = ~np.isnan(x)\n",
    "            x = x[x_valid]\n",
    "            w = wl_grid[x_valid]\n",
    "            if len(index)==1:\n",
    "                f.write('len==1\\n')\n",
    "                # a single point - plotting the outlier feature importance\n",
    "                label = 'index=%s, snr=%f, score=%f' % (index[0], snr[index[0]], weird_scores[index[0]])\n",
    "            else:\n",
    "                f.write('len>1\\n')\n",
    "                # Multiple points - plotting the cluster feature importance\n",
    "                label = '%d points selected - plotting the average' % len(index)\n",
    "\n",
    "        flux = hv.Curve((w,x), kdims=['w'],vdims=['flux']).opts(color='black').opts(norm=dict(framewise=True)).opts(tools=['hover'])\n",
    "    \n",
    "    return flux.relabel(label).opts(width=800, height=300, show_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples_dmap_callable(index):\n",
    "    \"\"\"\n",
    "    The callable function for the examples DynamicMap.\n",
    "    \"\"\"\n",
    "    spectra_dict = {i:hv.Curve((wl_grid,X_train_real[ind])).relabel('index=%s, snr=%f, score=%f' % (ind, snr[ind], weird_scores[ind])).opts(width=800, height=300, show_grid=True) for i,ind in enumerate(index)}\n",
    "\n",
    "    return hv.HoloMap(spectra_dict, kdims='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the T-SNE Points DynamicMap (Dynamic because of 2 color sources - score and snr)\n",
    "points_dmap = hv.DynamicMap(points_dmap_callable, kdims='ColorSource').redim.values(ColorSource=['score','snr'])\n",
    "points_dmap.opts(framewise=True, width=800, height=500, colorbar=True)\n",
    "selection = Selection1D(source=points_dmap) # creating a selection from the points\n",
    "\n",
    "# Creating the spectra DynamicMap - to load the spectra according to the selection from the selection of the T-SNE points.\n",
    "spectra_dmap = hv.DynamicMap(spectra_dmap_callable, kdims=[], streams=[selection])\n",
    "spectra_dmap.opts(norm=dict(framewise=True))\n",
    "\n",
    "# Building the layout full layout\n",
    "layout = (points_dmap + spectra_dmap).opts(merge_tools=False)\n",
    "layout.cols(1)\n",
    "\n",
    "pn.pane.HoloViews(layout, widget_location=\"top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_dmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "I_weird = np.argsort(weird_scores)\n",
    "i = 0\n",
    "print(weird_scores[I_weird[i]])\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(wl_grid, X_train_real[I_weird[i],:])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = data['gs'].iloc[I_train[I_train<len(data['gs'])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gs.iloc[6899]\n",
    "from NAURF import getUrl\n",
    "from astropy.io import fits\n",
    "url = getUrl(g)\n",
    "# Get data from .fits file (download from url)\n",
    "hdulist = fits.open(url, memmap=False, cache=False)\n",
    "data = hdulist[1].data\n",
    "specobjid = int(hdulist[2].data['specobjid'].item())\n",
    "hdulist.close()\n",
    "\n",
    "# Make sure the file matches the galaxy desired\n",
    "assert str(specobjid) == g['specobjid'], 'Files do not match galaxies dataframe'\n",
    "\n",
    "# Get flux values and wavelengths\n",
    "y = data['flux']\n",
    "x = np.array(10 ** data['loglam'], dtype=float)\n",
    "dy = data['ivar']\n",
    "hv.Curve((x,y)).opts(width=800, height=300, show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxilary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holomap = examples_dmap_callable(np.load(os.path.join(save_dir_path, 'cluster.npy'))).opts(width=800, height=300, show_grid=True)\n",
    "holomap_panel = pn.panel(holomap)\n",
    "plot = holomap_panel[0]\n",
    "widgets = holomap_panel[1]\n",
    "new_layout_panel = pn.Column(plot, widgets)\n",
    "new_layout_panel.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the mean spectra of the dataset\n",
    "hv.Curve((wl_grid, np.nanmean(X_train_real, axis=0))).opts(width=800, height=300, show_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the importances of the saved cluster\n",
    "index = np.load(os.path.join(save_dir_path, 'cluster.npy')) # loading the saved indices\n",
    "importance = create_wavelengths_importance(index, filt=False, norm=False)\n",
    "hv.Curve((wl_grid, importance)).opts(width=800, height=300, show_grid=True).opts(tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the importances of the saved cluster\n",
    "index = np.load(os.path.join(save_dir_path, 'cluster.npy')) # loading the saved indices\n",
    "importance = create_wavelengths_importance(index, filt=False, norm=False)\n",
    "hv.Curve((wl_grid, importance)).opts(width=800, height=300, show_grid=True).opts(tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the importances of the saved cluster\n",
    "index = np.load(os.path.join(save_dir_path, 'cluster.npy')) # loading the saved indices\n",
    "importance = create_wavelengths_importance(index, filt=False, norm=False)\n",
    "hv.Curve((wl_grid, importance)).opts(width=800, height=300, show_grid=True).opts(tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the marginal distribution \n",
    "wl = 5658\n",
    "wl_i = np.where(wl_grid==wl)[0][0]\n",
    "x_cluster = X_train_real[index,wl_i]\n",
    "x_real = X_train[y_train==1,wl_i]\n",
    "x_synth = X_train[y_train==2,wl_i]\n",
    "\n",
    "grid = np.linspace(0,3,20)\n",
    "cluster_freq, cluster_edges = np.histogram(x_cluster, grid, density=True)\n",
    "real_freq, real_edges = np.histogram(x_real[~np.isnan(x_real)], grid, density=True)\n",
    "synth_freq, synth_edges = np.histogram(x_synth[~np.isnan(x_synth)], grid, density=True)\n",
    "cluster_centers = (cluster_edges[:-1]+cluster_edges[1:])/2\n",
    "real_centers = (real_edges[:-1]+real_edges[1:])/2\n",
    "synth_centers = (synth_edges[:-1]+synth_edges[1:])/2\n",
    "comp = hv.Curve((cluster_centers, cluster_freq),label='cluster')*hv.Curve((real_centers, real_freq), label='real')*hv.Curve((synth_centers, synth_freq), label='synth')\n",
    "comp.opts(width=800, height=300, show_grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the decision paths dictionary\n",
    "from progressbar import progressbar\n",
    "decision_paths = dict()\n",
    "for k in progressbar(range(len(rf.estimators_))):\n",
    "    i_real = np.where(Y_hat_train_real[:,k]==1)[0] # indices of all samples which the k-th tree classified as \"real\"\n",
    "    i_sample,i_node = rf.estimators_[k].tree_.decision_path(X_train_real[i_real,rf.tree_i_start[k]:rf.tree_i_end[k]].astype(np.float32)).nonzero()\n",
    "    i_feature = rf.tree_i_start[k]+rf.estimators_[k].tree_.feature[i_node]\n",
    "    for i in range(len(i_real)):\n",
    "        temp_feature = i_feature[i_sample==i]\n",
    "        decision_paths[(i_real[i],k)] = temp_feature[:-1] # the last node is a leaf (not a decision node)\n",
    "        \n",
    "# saving it\n",
    "import pickle\n",
    "with open(decision_paths_path,'wb') as f:\n",
    "    pickle.dump(decision_paths, f)\n",
    "    \n",
    "# decision_paths_2 = [[decision_paths[(i,k)] if (i,k) in decision_paths else None for k in range(Y_hat_train_real.shape[1])] for i in range(Y_hat_train_real.shape[0])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
