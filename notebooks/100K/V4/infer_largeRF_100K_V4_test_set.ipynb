{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f163263e",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b519ea-69ed-4618-8b3c-79e01c73053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.23.4-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m543.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting progressbar2\n",
      "  Using cached progressbar2-4.0.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting sfdmap\n",
      "  Using cached sfdmap-0.1.1-py3-none-any.whl\n",
      "Collecting GPUtil\n",
      "  Using cached GPUtil-1.4.0-py3-none-any.whl\n",
      "Collecting botocore<1.27.0,>=1.26.4\n",
      "  Downloading botocore-1.26.4-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Using cached s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Downloading python_utils-3.2.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from sfdmap) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.4->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.27.0,>=1.26.4->boto3) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.4->boto3) (1.16.0)\n",
      "Installing collected packages: GPUtil, sfdmap, python-utils, jmespath, progressbar2, botocore, s3transfer, boto3\n",
      "Successfully installed GPUtil-1.4.0 boto3-1.23.4 botocore-1.26.4 jmespath-1.0.0 progressbar2-4.0.0 python-utils-3.2.3 s3transfer-0.5.2 sfdmap-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 progressbar2 sfdmap GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe697e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import boto3\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# local files paths\n",
    "local_home_dir_path = os.path.expanduser(\"~\")\n",
    "local_work_dir_path = os.path.join(local_home_dir_path, 'git')\n",
    "local_code_dir_path = os.path.join(local_work_dir_path , 'code')\n",
    "\n",
    "# S3 file paths\n",
    "endpoint_url = 'https://s3-west.nrp-nautilus.io'\n",
    "bucket_name = 'tau-astro'\n",
    "prefix = 'almogh'\n",
    "s3_work_dir_path = os.path.join(prefix, 'workdir3')\n",
    "s3_saves_dir_path = os.path.join(s3_work_dir_path , 'model_saves')\n",
    "s3_data_dir_path = os.path.join(s3_work_dir_path , 'data')\n",
    "s3_v2_data_ver_dir_path = os.path.join(s3_data_dir_path,'100K_V2')\n",
    "s3_v4_data_ver_dir_path = os.path.join(s3_data_dir_path,'100K_V4')\n",
    "\n",
    "s3_client = boto3.client(\"s3\", endpoint_url=endpoint_url)\n",
    "\n",
    "# adding code folder to path\n",
    "sys.path.insert(1, local_code_dir_path)\n",
    "from s3 import to_s3_npy, to_s3_pkl, from_s3_npy, from_s3_pkl, to_s3_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17faf82a",
   "metadata": {},
   "source": [
    "# Infer RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcb473",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51dc9b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and creating dataset\n",
      "loading from uri: s3://tau-astro/almogh/workdir3/data/100K_V4/gs_test_V4.pkl\n",
      "loading from uri: s3://tau-astro/almogh/workdir3/data/100K_V2/spec.npy\n",
      "loading from uri: s3://tau-astro/almogh/workdir3/data/wl_grid.npy\n",
      "loading from uri: s3://tau-astro/almogh/workdir3/data/100K_V4/wl_100K_V4.npy\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print('Loading data and creating dataset')\n",
    "gs = from_s3_pkl(s3_client, bucket_name, os.path.join(s3_v4_data_ver_dir_path,'gs_test_V4.pkl'))\n",
    "X = from_s3_npy(s3_client, bucket_name, os.path.join(s3_v2_data_ver_dir_path, 'spec.npy'))\n",
    "full_wl_grid = from_s3_npy(s3_client, bucket_name, os.path.join(s3_data_dir_path, 'wl_grid.npy'))\n",
    "wl_grid = from_s3_npy(s3_client, bucket_name, os.path.join(s3_v4_data_ver_dir_path, 'wl_100K_V4.npy'))\n",
    "start_i = (np.abs(full_wl_grid - wl_grid[0])).argmin()\n",
    "end_i = 1+(np.abs(full_wl_grid - wl_grid[-1])).argmin()\n",
    "X = X[gs.index, start_i:end_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824c2646-6b12-4439-86a6-d92f7e86a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(X)), 'NaN!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc57c35",
   "metadata": {},
   "source": [
    "## Load RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ed43ac-2ad4-416d-a305-b94befc0c4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from folder (S3): almogh/workdir3/model_saves/RF/simple___2022_05_10___11_24_58___100K_V4_full_data_set\n",
      "loading from uri: s3://tau-astro/almogh/workdir3/model_saves/RF/simple___2022_05_10___11_24_58___100K_V4_full_data_set/crf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.1 when using version 1.1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "load_RF_name = 'simple___2022_05_10___11_24_58___100K_V4_full_data_set'\n",
    "s3_load_dir_path = os.path.join(s3_saves_dir_path, 'RF', load_RF_name)\n",
    "print('loading from folder (S3): {0}'.format(s3_load_dir_path))\n",
    "\n",
    "from CustomRandomForest import CustomRandomForest\n",
    "rf = CustomRandomForest.load_s3(s3_client, bucket_name, os.path.join(s3_load_dir_path, 'crf.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d517f6",
   "metadata": {},
   "source": [
    "## Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550444f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying the RF (calculate leaves)\n",
      "apply: starting 500 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting fully\n",
      "Calculating the similarity matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2146 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3010 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3496 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4018 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4576 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5170 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5800 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6466 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7168 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8084 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assembling the matrix.\n"
     ]
    }
   ],
   "source": [
    "print('Applying the RF (calculate leaves)')\n",
    "X_leaves = rf.apply(X)\n",
    "\n",
    "print('Predicting fully')\n",
    "Y_hat = rf.predict_full_from_leaves(X_leaves)\n",
    "\n",
    "print('Calculating the similarity matrix')\n",
    "from CustomRandomForest import build_similarity_matrix\n",
    "sim_mat = build_similarity_matrix(X_leaves, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c107aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the distance matrix and weirdness scores\n"
     ]
    }
   ],
   "source": [
    "print('Calculating the distance matrix and weirdness scores')\n",
    "dist_mat_hat_test_set = 1 - sim_mat\n",
    "weird_scores_hat_test_set = np.mean(dist_mat_hat_test_set, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d08c57-a80e-4b3f-8cfc-08a08df52906",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b84733-9476-42bb-a7d4-b8b318d86ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the weirdness scores\n",
      "saving to uri: s3://tau-astro/almogh/workdir3/model_saves/RF/simple___2022_05_10___11_24_58___100K_V4_full_data_set/weird_scores_hat_test_set.npy\n",
      "Saving the dissimilarity matrix\n",
      "saving to uri: s3://tau-astro/almogh/workdir3/model_saves/RF/simple___2022_05_10___11_24_58___100K_V4_full_data_set/dist_mat_hat_test_set.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Saving the weirdness scores')\n",
    "to_s3_npy(weird_scores_hat_test_set, s3_client, bucket_name, os.path.join(s3_load_dir_path, 'weird_scores_hat_test_set.npy'))\n",
    "\n",
    "print('Saving the dissimilarity matrix')\n",
    "to_s3_npy(dist_mat_hat_test_set, s3_client, bucket_name, os.path.join(s3_load_dir_path, 'dist_mat_hat_test_set.npy'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
